## Installation
To install the package directly from the GitHub repository, use the following command:

```bash
pip install git+https://github.com/ssangjun706/my_package.git
```

## Upgrade
To update the package to the latest version:

```bash
pip install --upgrade git+https://github.com/ssangjun706/my_package.git
```

## Module: `parallel`
It offers simplified PyTorch distributed training. It focuses on making distributed workflows more accessible and removing unnecessary boilerplate.
> It does not provide any additional features beyond the core functionality.

### Features
- **`DistributedTrainer`**: A training framework that supports both return and yield values during distributed training.

